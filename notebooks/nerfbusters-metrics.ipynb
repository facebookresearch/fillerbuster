{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a4bed2a-a472-45ed-9035-ca200046225d",
   "metadata": {},
   "source": [
    "# Nerfbusters Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3477ec4-3500-48da-8c30-026886608d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import mediapy\n",
    "import numpy as np\n",
    "\n",
    "methods_dict = {}\n",
    "methods_dict[\"nerfbusters\"] = [\"gsplat\", \"nerfiller\", \"cat3d\", \"mvinpaint\"]\n",
    "methods_dict[\"nerfiller\"] = [\"mask\", \"gsplat\", \"nerfiller-no-new-views\", \"mvinpaint-no-new-views\"]\n",
    "\n",
    "datasets_dict = {\n",
    "    \"nerfbusters\": [\n",
    "        \"aloe\",\n",
    "        \"art\",\n",
    "        \"car\",\n",
    "        \"century\",\n",
    "        \"flowers\",\n",
    "        \"garbage\",\n",
    "        \"picnic\",\n",
    "        \"pikachu\",\n",
    "        \"pipe\",\n",
    "        \"plant\",\n",
    "        \"roses\",\n",
    "        \"table\",\n",
    "    ],\n",
    "    \"nerfiller\": [\"bear\", \"billiards\", \"boot\", \"cat\", \"drawing\", \"dumptruck\", \"norway\", \"office\", \"turtle\"],\n",
    "}\n",
    "\n",
    "dataset_name = \"nerfbusters\"\n",
    "datasets = datasets_dict[dataset_name]\n",
    "methods = methods_dict[dataset_name]\n",
    "folder = Path(f\"/mnt/home/ethanjohnweber/data/{dataset_name}-renders\")\n",
    "output = Path(f\"/mnt/home/ethanjohnweber/data/{dataset_name}\")\n",
    "save_images = False\n",
    "save_video = False\n",
    "seconds = 10\n",
    "num_pairs = 20\n",
    "# pairs1 = np.random.rand(num_pairs, 1)\n",
    "# pairs2 = pairs1 + (np.random.rand(num_pairs, 1) / 4.0)\n",
    "# pairs = np.concatenate([pairs1, pairs2], axis=-1)\n",
    "# pairs = np.clip(pairs, 0, 0.99)\n",
    "# pairs1 = np.linspace(0.0, .9, num_pairs)\n",
    "# pairs2 = np.linspace(0.05, .95, num_pairs)\n",
    "pairs1 = np.linspace(0.1, 0.8, num_pairs)\n",
    "pairs2 = np.linspace(0.2, 0.9, num_pairs)\n",
    "pairs = np.concatenate([pairs1[..., None], pairs2[..., None]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca806ef5-2706-4d88-b4a4-6941a6f86404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5b1b30e-c8fa-4295-9da3-82d2f1e3c556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────── <span style=\"font-weight: bold\">viser</span> ───────────────╮\n",
       "│             ╷                       │\n",
       "│   HTTP      │ http://0.0.0.0:8891   │\n",
       "│   Websocket │ ws://0.0.0.0:8891     │\n",
       "│             ╵                       │\n",
       "╰─────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────── \u001b[1mviser\u001b[0m ───────────────╮\n",
       "│             ╷                       │\n",
       "│   HTTP      │ http://0.0.0.0:8891   │\n",
       "│   Websocket │ ws://0.0.0.0:8891     │\n",
       "│             ╵                       │\n",
       "╰─────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import viser\n",
    "\n",
    "viser_port = 8890\n",
    "if \"viser_server\" not in globals():\n",
    "    # only run this once per Python process start\n",
    "    viser_server = viser.ViserServer(port=viser_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b79a537-594c-43a6-aaab-ef7defaa1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76dceada-7ec7-49c0-b1b6-ae7b77503a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kornia\n",
    "import torch\n",
    "from kornia.feature import LoFTR\n",
    "\n",
    "device = \"cuda:0\"\n",
    "matcher = LoFTR(\"outdoor\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e9a588b-8996-455f-abe3-a99c5cc8a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_camera(name, c2w, image):\n",
    "    import viser.transforms as vtf\n",
    "\n",
    "    R = vtf.SO3.from_matrix(c2w[:3, :3])\n",
    "    R = R @ vtf.SO3.from_x_radians(np.pi)\n",
    "    camera_handle = viser_server.scene.add_camera_frustum(\n",
    "        name=name, fov=1.0, scale=0.2, aspect=1, image=image, wxyz=R.wxyz, position=c2w[:3, 3]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4d72c96-27b8-4c36-825b-4c0761a7a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_angular_error_batch(rotation1, rotation2):\n",
    "    # https://github.com/jasonyzhang/RayDiffusion/blob/main/ray_diffusion/eval/utils.py#L50\n",
    "    R_rel = np.einsum(\"Bij,Bjk ->Bik\", rotation2, rotation1.transpose(0, 2, 1))\n",
    "    t = (np.trace(R_rel, axis1=1, axis2=2) - 1) / 2\n",
    "    theta = np.arccos(np.clip(t, -1, 1))\n",
    "    return theta * 180 / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1826523f-7449-4d17-900c-1720c3918957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(video, cameras, pair, mask_video=None, visualize=False):\n",
    "    num_frames = len(video)\n",
    "    idx0 = int(pair[0] * num_frames)\n",
    "    idx1 = int(pair[1] * num_frames)\n",
    "    camera0 = cameras[str(idx0)]\n",
    "    camera1 = cameras[str(idx1)]\n",
    "    image0 = (torch.from_numpy(video[idx0])[None].permute(0, 3, 1, 2) / 255.0).to(device)\n",
    "    image1 = (torch.from_numpy(video[idx1])[None].permute(0, 3, 1, 2) / 255.0).to(device)\n",
    "\n",
    "    if mask_video is not None:\n",
    "        from mvinpaint.utils.visualization_utils import Colors\n",
    "\n",
    "        target_color = torch.tensor(Colors.NEON_YELLOW.value).to(device)[None, :, None, None]\n",
    "        mask_image0 = (torch.from_numpy(mask_video[idx0])[None].permute(0, 3, 1, 2) / 255.0).to(device)\n",
    "        mask_image1 = (torch.from_numpy(mask_video[idx1])[None].permute(0, 3, 1, 2) / 255.0).to(device)\n",
    "        mask_image0 = torch.abs(mask_image0 - target_color) < 0.05\n",
    "        mask_image1 = torch.abs(mask_image1 - target_color) < 0.05\n",
    "        mask_image0 = mask_image0[:, 0:1] & mask_image0[:, 1:2] & mask_image0[:, 2:3]\n",
    "        mask_image1 = mask_image1[:, 0:1] & mask_image1[:, 1:2] & mask_image1[:, 2:3]\n",
    "        # image0 *= mask_image0\n",
    "        # image1 *= mask_image1\n",
    "\n",
    "    image0_g = kornia.color.rgb_to_grayscale(image0)\n",
    "    image1_g = kornia.color.rgb_to_grayscale(image1)\n",
    "    input_dict = {\"image0\": image0_g, \"image1\": image1_g}\n",
    "    with torch.inference_mode():\n",
    "        correspondences = matcher(input_dict)\n",
    "\n",
    "    c2w1 = torch.eye(4)[None]\n",
    "    c2w1[0, :3, :] = torch.tensor(camera0[\"camera_to_world\"])\n",
    "    c2w2 = torch.eye(4)[None]\n",
    "    c2w2[0, :3, :] = torch.tensor(camera1[\"camera_to_world\"])\n",
    "    if visualize:\n",
    "        draw_camera(\"/orig/0\", c2w1[0], (image0[0].permute(1, 2, 0) * 255).cpu().numpy().astype(\"uint8\"))\n",
    "        draw_camera(\"/orig/1\", c2w2[0], (image1[0].permute(1, 2, 0) * 255).cpu().numpy().astype(\"uint8\"))\n",
    "    c2w2 = torch.bmm(torch.linalg.inv(c2w1), c2w2)\n",
    "    c2w1 = torch.bmm(torch.linalg.inv(c2w1), c2w1)\n",
    "    if visualize:\n",
    "        draw_camera(\"/cameras/0\", c2w1[0], (image0[0].permute(1, 2, 0) * 255).cpu().numpy().astype(\"uint8\"))\n",
    "        draw_camera(\"/cameras/1\", c2w2[0], (image1[0].permute(1, 2, 0) * 255).cpu().numpy().astype(\"uint8\"))\n",
    "\n",
    "    # check if correspondence is in the mask\n",
    "    keypoints0 = correspondences[\"keypoints0\"].to(device)\n",
    "    keypoints1 = correspondences[\"keypoints1\"].to(device)\n",
    "    if mask_video is not None:\n",
    "        mask_value0 = mask_image0[:, :, keypoints0[..., 1].long(), keypoints0[..., 0].long()].flatten()\n",
    "        mask_value1 = mask_image1[:, :, keypoints1[..., 1].long(), keypoints1[..., 0].long()].flatten()\n",
    "        mask_both = (mask_value0 == 1) & (mask_value1 == 1)\n",
    "        keypoints0 = keypoints0[mask_both]\n",
    "        keypoints1 = keypoints1[mask_both]\n",
    "\n",
    "    image = (torch.cat([image0, image1], dim=-1)[0].permute(1, 2, 0) * 255).cpu().numpy().astype(\"uint8\")\n",
    "    for idx in range(0, len(keypoints0), 20):\n",
    "        (x0, y0) = keypoints0[idx]\n",
    "        (x1, y1) = keypoints1[idx]\n",
    "        color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "        cv2.line(image, (int(x0), int(y0)), (int(x1) + 512, int(y1)), color, 2)\n",
    "\n",
    "    K1 = torch.tensor([[camera0[\"fx\"], 0, camera0[\"cx\"]], [0, camera0[\"fy\"], camera0[\"cy\"]], [0, 0, 1]])[None].to(\n",
    "        device\n",
    "    )\n",
    "    K2 = torch.tensor([[camera1[\"fx\"], 0, camera1[\"cx\"]], [0, camera1[\"fy\"], camera1[\"cy\"]], [0, 0, 1]])[None].to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    points1 = keypoints0[None].clone()\n",
    "    points2 = keypoints1[None].clone()\n",
    "    F_mat = kornia.geometry.epipolar.find_fundamental(points1, points2, weights=correspondences[\"confidence\"][None])\n",
    "    E_mat = kornia.geometry.epipolar.essential_from_fundamental(F_mat, K1, K2)\n",
    "    R, t, points = kornia.geometry.epipolar.motion_from_essential_choose_solution(\n",
    "        E_mat, K1, K2, points1, points2, mask=None\n",
    "    )\n",
    "\n",
    "    # R[..., 1:3] *= -1\n",
    "    # t[..., 1, 0] = -t[..., 1, 0]\n",
    "    # t[..., 2, 0] = -t[..., 2, 0]\n",
    "\n",
    "    # temp = torch.tensor([\n",
    "    #     [1, 0, 0, 0],\n",
    "    #     [0, -1, 0, 0],\n",
    "    #     [0, 0, -1, 0],\n",
    "    #     [0, 0, 0, 1]\n",
    "    # ])[None].to(device).float()\n",
    "    # print(temp.shape)\n",
    "    # print(points.shape)\n",
    "    # print(temp[0,:3,:3].shape)\n",
    "    # points = points @ temp[0,:3,:3].permute(1,0)\n",
    "\n",
    "    gt_trans_norm = torch.linalg.norm(c2w2[0, :3, 3])\n",
    "\n",
    "    estimated_rel = torch.eye(4)[None].to(device)\n",
    "    estimated_rel[:, :3, :3] = R\n",
    "    estimated_rel[:, :3, 3:4] = t * gt_trans_norm\n",
    "    estimated_rel = torch.inverse(estimated_rel)\n",
    "\n",
    "    Rx = torch.tensor([[1, 0, 0], [0, -1, 0], [0, 0, -1]])[None].to(device).float()\n",
    "    points = points @ Rx[0].permute(1, 0)\n",
    "    temp = torch.tensor([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])[None].to(device).float()\n",
    "\n",
    "    prime_0 = (\n",
    "        torch.tensor(\n",
    "            [\n",
    "                [1, 0, 0, 0],\n",
    "                [0, -1, 0, 0],\n",
    "                [0, 0, -1, 0],\n",
    "                [0, 0, 0, 1],\n",
    "            ]\n",
    "        )[None]\n",
    "        .to(device)\n",
    "        .float()\n",
    "    )\n",
    "    prime_1 = torch.bmm(estimated_rel, prime_0)\n",
    "\n",
    "    prime_0 = torch.bmm(temp, prime_0)\n",
    "    prime_1 = torch.bmm(temp, prime_1)\n",
    "\n",
    "    if visualize:\n",
    "        draw_camera(\n",
    "            \"/cameras/0_prime\", prime_0[0].cpu(), (image0[0].permute(1, 2, 0) * 255).cpu().numpy().astype(\"uint8\")\n",
    "        )\n",
    "        draw_camera(\n",
    "            \"/cameras/1_prime\", prime_1[0].cpu(), (image1[0].permute(1, 2, 0) * 255).cpu().numpy().astype(\"uint8\")\n",
    "        )\n",
    "        viser_server.scene.add_point_cloud(\n",
    "            \"/points\",\n",
    "            points=points.view(-1, 3).cpu().numpy(),\n",
    "            colors=(1.0, 0, 0),\n",
    "            point_size=0.03,\n",
    "            point_shape=\"circle\",\n",
    "        )\n",
    "        mediapy.show_image(image)\n",
    "\n",
    "    error = compute_angular_error_batch(c2w2[:, :3, :3].cpu().numpy(), prime_1[:, :3, :3].cpu().numpy())\n",
    "    return float(error[0])\n",
    "\n",
    "\n",
    "# error = get_metric(video, cameras, pairs[1], mask_video=mask_video, visualize=True)\n",
    "# print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c64ebcdc-a760-4721-bf66-314493e912b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nerfbusters'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b62f9f-5acd-4413-a066-b2eca12d9a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aloe\n",
      "gsplat\n",
      "nerfiller\n",
      "cat3d\n",
      "mvinpaint\n",
      "art\n",
      "gsplat\n",
      "nerfiller\n",
      "cat3d\n",
      "mvinpaint\n",
      "car\n",
      "gsplat\n",
      "nerfiller\n",
      "cat3d\n",
      "mvinpaint\n",
      "century\n",
      "gsplat\n",
      "nerfiller\n",
      "cat3d\n",
      "mvinpaint\n",
      "flowers\n",
      "gsplat\n",
      "nerfiller\n",
      "cat3d\n",
      "mvinpaint\n",
      "garbage\n",
      "gsplat\n",
      "nerfiller\n",
      "cat3d\n",
      "mvinpaint\n",
      "picnic\n",
      "gsplat\n",
      "nerfiller\n",
      "cat3d\n",
      "mvinpaint\n",
      "pikachu\n",
      "gsplat\n",
      "nerfiller\n",
      "cat3d\n",
      "mvinpaint\n",
      "pipe\n",
      "gsplat\n",
      "nerfiller\n",
      "cat3d\n",
      "mvinpaint\n",
      "plant\n",
      "gsplat\n",
      "nerfiller\n",
      "cat3d\n",
      "mvinpaint\n",
      "roses\n",
      "gsplat\n",
      "nerfiller\n",
      "cat3d\n",
      "mvinpaint\n",
      "table\n",
      "gsplat\n",
      "nerfiller\n",
      "cat3d\n",
      "mvinpaint\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "metrics = defaultdict(dict)\n",
    "all_video = []\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    videos = []\n",
    "    for method in methods:\n",
    "        print(method)\n",
    "        filename = Path(sorted(list((folder / dataset / method).iterdir()))[-1])\n",
    "        cameras_filename = Path(str(filename).replace(\".mp4\", \".json\"))\n",
    "        with open(cameras_filename) as f:\n",
    "            cameras = json.load(f)\n",
    "        video = mediapy.read_video(filename)\n",
    "        # if dataset_name == \"nerfiller\":\n",
    "        #     filename = Path(sorted(list((folder / dataset / \"mask\").iterdir()))[-1])\n",
    "        #     mask_video = mediapy.read_video(filename)\n",
    "        # else:\n",
    "        #     mask_video = None\n",
    "        mask_video = None\n",
    "        errors = []\n",
    "        for pair in pairs:\n",
    "            try:\n",
    "                error = get_metric(video, cameras, pair, mask_video=mask_video, visualize=False)\n",
    "                errors.append(error)\n",
    "            except:\n",
    "                errors.append(360.0)\n",
    "        # print(errors)\n",
    "        errors = np.array(errors)\n",
    "        metrics[dataset][method] = errors\n",
    "        if save_images:\n",
    "            for i in range(len(video)):\n",
    "                filename = output / f\"{dataset}/{method}/image-{i:06d}.jpg\"\n",
    "                print(filename)\n",
    "                filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "                mediapy.write_image(filename, video[i])\n",
    "        if save_video:\n",
    "            print(\"todo: save video\")\n",
    "        videos.append(video)\n",
    "    # mediapy.show_videos(videos, fps=len(cat_video)/seconds)\n",
    "    cat_video = np.concatenate(videos, axis=2)\n",
    "    all_video.append(cat_video)\n",
    "cat_all_video = np.concatenate(all_video, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b14cb0-b447-46fb-bdb2-f22c6acd5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset in datasets:\n",
    "#     for method in methods:\n",
    "#         print(dataset, method, metrics[dataset][method].mean())\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4994ae7a-315e-4783-9adc-1ab12538edb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds = np.arange(10, 30, 1)\n",
    "thresholds = np.arange(0, 30, 1)\n",
    "print(f\"thresholds: {thresholds}\")\n",
    "rra_dict = defaultdict(dict)\n",
    "for dataset in datasets:\n",
    "    for method in methods:\n",
    "        for thr in thresholds:\n",
    "            rra = (metrics[dataset][method] < thr).mean()\n",
    "            value = rra * (1 / len(metrics))\n",
    "            try:\n",
    "                rra_dict[method][thr] += value\n",
    "            except:\n",
    "                rra_dict[method][thr] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb0ada1-8aef-405f-8c6b-8cc76cc2ef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rra_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5e943f-cb1e-465c-b181-3b724e8e3512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# for method in methods:\n",
    "colors = [\"#3498db\", \"#f1c40f\", \"#2ecc71\", \"#e74c3c\"]\n",
    "for idx, (method, name) in enumerate(\n",
    "    [(\"mvinpaint\", \"Fillerbuster\"), (\"cat3d\", \"CAT3D-Imp.\"), (\"gsplat\", \"GSplat\"), (\"nerfiller\", \"NeRFiller\")]\n",
    "):\n",
    "    # for idx, (method, name) in enumerate([(\"mvinpaint\", \"A\"), (\"cat3d\", \"B\"), (\"gsplat\", \"C\"), (\"nerfiller\", \"D\")]):\n",
    "    # for idx, method in enumerate(methods):\n",
    "    #     print(method)\n",
    "    #     name = method\n",
    "    x = sorted(rra_dict[method].keys())\n",
    "    y = [rra_dict[method][key] for key in x]\n",
    "    fig.add_trace(go.Scatter(x=x, y=y, mode=\"lines\", name=name, line=dict(width=6, color=colors[idx])))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"Relative Rotation Accuracy\", x=0.5, y=0.92, xanchor=\"center\"),\n",
    "    # xaxis_title='Degrees',\n",
    "    # xaxis_title=dict(\n",
    "    #     text='Degrees',\n",
    "    #     x=0.5,y=0.0,\n",
    "    #     xanchor='center'\n",
    "    # ),\n",
    "    yaxis_title=\"RRA @ Degrees\",\n",
    "    paper_bgcolor=\"white\",\n",
    "    plot_bgcolor=\"white\",\n",
    "    font=dict(size=16, family=\"Helvetica\"),\n",
    "    legend=dict(orientation=\"v\", yanchor=\"top\", xanchor=\"right\", x=1.2, y=1.0),\n",
    "    xaxis=dict(showgrid=True, gridwidth=1, gridcolor=\"black\"),\n",
    "    yaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridwidth=1,\n",
    "        gridcolor=\"black\",\n",
    "        range=[0, 1.01],  # Add some padding\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, t=50, b=0),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"rra_plot.pdf\", width=800, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c910c62-0852-4fef-a7f9-808d7949f6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302b176-5f47-4bce-a568-5f612cb1521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mediapy.show_video(cat_all_video, fps=len(cat_video)/seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca975d18-c379-477d-9ed1-a045929a2ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe5eb12-e952-4863-a83e-a2ef4009cf64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9846fb5a-aa6b-4266-9534-f4eb6d9ab3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252fb0a3-aff0-4e6f-b1cd-c3e7d5b7dffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cab937-ace2-4030-94f3-b2b8a428e1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
